{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Spring 2021 - CA1\n",
    "\n",
    "prepared by Sajjad Pakdaman Savoji - 810195517"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/savoji/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/savoji/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from libs import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_train_path = \"Data/HateEval/train.csv\"\n",
    "hate_dev_path = \"Data/HateEval/dev.csv\"\n",
    "hate_test_path = \"Data/HateEval/test.csv\"\n",
    "off_train_path = \"Data/OffenseEval/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_train, hate_dev, hate_test, off_train = load_data(hate_train_path, hate_dev_path, hate_test_path, off_train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_train['text'] = hate_train['text'].apply(costum_preprocessing)\n",
    "hate_dev['text'] = hate_dev['text'].apply(costum_preprocessing)\n",
    "off_train['text'] = off_train['text'].apply(costum_preprocessing)\n",
    "hate_test['text'] = hate_test['text'].apply(costum_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(hate_train, hate_dev):\n",
    "#     prep_options = [lemma, stem]\n",
    "#     prep_option_names = ['lemma', 'stem']\n",
    "    model_options = [Laplace]\n",
    "    model_option_names = [\"Laplace\"]\n",
    "    tokenizer_options = [word_tokenize, char_tokenizer]\n",
    "    tokenizer_option_names = [\"word-level\", \"char-level\"]\n",
    "    \n",
    "    records = []\n",
    "    counter = 0\n",
    "    for tknz, tknz_name in zip(tokenizer_options, tokenizer_option_names):\n",
    "        for model, model_name in zip(model_options, model_option_names):\n",
    "#             for opt, opt_name in zip(prep_options, prep_option_names):\n",
    "            counter += 1\n",
    "            opts = []\n",
    "            opt_names = []\n",
    "\n",
    "            train = prep(hate_train, opts, tknz)\n",
    "            dev   = prep(hate_dev,   opts, tknz)\n",
    "            lm_1_0, lm_1_1, lm_2_0, lm_2_1 = train_models(train, model)\n",
    "\n",
    "            train_pred_labels_2 = predict_labels(train, lm_2_0, lm_2_1, 2)\n",
    "            train_pred_labels_1 = predict_labels(train, lm_1_0, lm_1_1, 1)\n",
    "            dev_pred_labels_2   = predict_labels(dev  , lm_2_0, lm_2_1, 2)\n",
    "            dev_pred_labels_1   = predict_labels(dev  , lm_1_0, lm_1_1, 1)\n",
    "\n",
    "            rec = evaluate_model(train.label, train_pred_labels_1, create_desc(tknz_name, model_name, opt_names, 1, 'train'))\n",
    "            records.append(rec)\n",
    "            rec = evaluate_model(train.label, train_pred_labels_2, create_desc(tknz_name, model_name, opt_names, 2, 'train'))\n",
    "            records.append(rec)\n",
    "            rec = evaluate_model(dev.label  , dev_pred_labels_1, create_desc(tknz_name, model_name, opt_names, 1, 'dev'))\n",
    "            records.append(rec)\n",
    "            rec = evaluate_model(dev.label  , dev_pred_labels_2, create_desc(tknz_name, model_name, opt_names, 2, 'dev'))\n",
    "            records.append(rec)\n",
    "            print(f'{counter}/{len(tokenizer_options)*len(model_options)}')\n",
    "                \n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|unigram|train|word-level|Laplace|basic prep|\n",
      "|bigram|train|word-level|Laplace|basic prep|\n",
      "|unigram|dev|word-level|Laplace|basic prep|\n",
      "|bigram|dev|word-level|Laplace|basic prep|\n",
      "1/2\n",
      "|unigram|train|char-level|Laplace|basic prep|\n",
      "|bigram|train|char-level|Laplace|basic prep|\n",
      "|unigram|dev|char-level|Laplace|basic prep|\n",
      "|bigram|dev|char-level|Laplace|basic prep|\n",
      "2/2\n"
     ]
    }
   ],
   "source": [
    "records = train_function(hate_train, hate_dev)\n",
    "df = create_df_from_records(records, 'metrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make data balanced using offensive train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = len(hate_train[hate_train.label==0]) - len(hate_train[hate_train.label==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional = off_train[off_train.label==1][0:dif]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data = pd.concat([hate_train, additional])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(balanced_data[balanced_data.label==0]) - len(balanced_data[balanced_data.label==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|unigram|train|word-level|Laplace|basic prep|\n",
      "|bigram|train|word-level|Laplace|basic prep|\n",
      "|unigram|dev|word-level|Laplace|basic prep|\n",
      "|bigram|dev|word-level|Laplace|basic prep|\n",
      "1/2\n",
      "|unigram|train|char-level|Laplace|basic prep|\n",
      "|bigram|train|char-level|Laplace|basic prep|\n",
      "|unigram|dev|char-level|Laplace|basic prep|\n",
      "|bigram|dev|char-level|Laplace|basic prep|\n",
      "2/2\n"
     ]
    }
   ],
   "source": [
    "records = train_function(balanced_data, hate_dev)\n",
    "# df = create_df_from_records(records, 'metrics-balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(hate_train, hate_dev, hate_test):\n",
    "    model_options = [Laplace]\n",
    "    model_option_names = [\"Laplace\"]\n",
    "    tokenizer_options = [word_tokenize]\n",
    "    tokenizer_option_names = [\"word-level\"]\n",
    "    \n",
    "    for tknz, tknz_name in zip(tokenizer_options, tokenizer_option_names):\n",
    "        for model, model_name in zip(model_options, model_option_names):\n",
    "            opts = []\n",
    "            opt_names = []\n",
    "\n",
    "            train = prep(hate_train, opts, tknz)\n",
    "            dev   = prep(hate_dev,   opts, tknz)\n",
    "            test  = prep(hate_test,  opts, tknz)\n",
    "            \n",
    "            lm_1_0, lm_1_1, lm_2_0, lm_2_1 = train_models(train, model)\n",
    "\n",
    "#             train_pred_labels_1 = predict_labels(train, lm_1_0, lm_1_1, 1)\n",
    "#             dev_pred_labels_1   = predict_labels(dev,   lm_1_0, lm_1_1, 1)\n",
    "            test_pred_labels_1  = predict_labels(test,  lm_1_0, lm_1_1, 1)\n",
    "\n",
    "#             evaluate_model(train.label, train_pred_labels_1, create_desc(tknz_name, model_name, opt_names, 1, 'train'))\n",
    "#             evaluate_model(dev.label  , dev_pred_labels_1, create_desc(tknz_name, model_name, opt_names, 1, 'dev'))\n",
    "            \n",
    "            test_final = pd.read_csv(hate_test_path)\n",
    "            test_final.label = test_pred_labels_1\n",
    "            test_final.to_csv('./Res/test_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_function(balanced_data, hate_dev, hate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
